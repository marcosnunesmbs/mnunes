---
name: 'analyze-traces'
description: 'Automated analysis of Chrome DevTools Performance Traces to compare performance metrics before and after optimizations, generating comprehensive reports with visualizations and actionable insights.'
---

# Performance Trace Analysis - Copilot Command

## Command Trigger
`/analyze-traces`

## Purpose
Automated analysis of Chrome DevTools Performance Traces to compare performance metrics before and after optimizations, generating comprehensive reports with visualizations and actionable insights.

## Expected Input
User must provide **TWO Chrome DevTools Performance Trace files** (.json format):
1. **BEFORE trace** - Baseline performance before optimizations
2. **AFTER trace** - Performance after implementing optimizations

The user will either:
- Attach files directly in the conversation
- Provide file paths to traces in the workspace
- Reference trace directories

## Execution Steps

### Step 1: Validate Input
1. Confirm you have received **2 trace files**
2. Verify both files are valid JSON
3. Check that both files contain the required structure:
   - `metadata.modifications.initialBreadcrumb.window`
   - `traceEvents` array
   - `metadata.startTime`
4. If validation fails, request correct files from user

### Step 2: Identify Traces
1. Determine which trace is BEFORE and which is AFTER by:
   - Timestamp (`metadata.startTime` - older = BEFORE)
   - File name pattern (if contains "before", "after", "baseline", "optimized")
   - Ask user if unclear
2. Store trace identifiers for reporting

### Step 3: Create Analysis Directory Structure
Create the following structure in `new-site/Traces/`:
```
Traces/
‚îú‚îÄ‚îÄ Trace-[TIMESTAMP-BEFORE]/
‚îÇ   ‚îî‚îÄ‚îÄ Trace-[TIMESTAMP-BEFORE].json
‚îú‚îÄ‚îÄ Trace-[TIMESTAMP-AFTER]/
‚îÇ   ‚îî‚îÄ‚îÄ Trace-[TIMESTAMP-AFTER].json
‚îú‚îÄ‚îÄ Reports/
‚îÇ   ‚îî‚îÄ‚îÄ (will be populated with analysis files)
‚îú‚îÄ‚îÄ analyze-traces.js
‚îî‚îÄ‚îÄ analysis-data.json
```

### Step 4: Create Analysis Script
Create `new-site/Traces/analyze-traces.js` with the following logic:

```javascript
const fs = require('fs');
const path = require('path');

// Load both traces
const beforePath = '[PATH_TO_BEFORE_TRACE]';
const afterPath = '[PATH_TO_AFTER_TRACE]';

const before = JSON.parse(fs.readFileSync(beforePath, 'utf8'));
const after = JSON.parse(fs.readFileSync(afterPath, 'utf8'));

// Extract metrics
const analysis = {
  duration: {
    before: before.metadata.modifications.initialBreadcrumb.window.range,
    after: after.metadata.modifications.initialBreadcrumb.window.range,
    beforeMs: parseFloat((before.metadata.modifications.initialBreadcrumb.window.range / 1000).toFixed(2)),
    afterMs: parseFloat((after.metadata.modifications.initialBreadcrumb.window.range / 1000).toFixed(2)),
    improvement: parseFloat(((before.metadata.modifications.initialBreadcrumb.window.range - after.metadata.modifications.initialBreadcrumb.window.range) / before.metadata.modifications.initialBreadcrumb.window.range * 100).toFixed(2))
  },
  events: {
    before: before.traceEvents.length,
    after: after.traceEvents.length,
    reduction: parseFloat(((before.traceEvents.length - after.traceEvents.length) / before.traceEvents.length * 100).toFixed(2))
  },
  resources: {
    before: (before.metadata.resources || []).length,
    after: (after.metadata.resources || []).length,
    beforeSizeKB: calculateResourceSize(before.metadata.resources || []),
    afterSizeKB: calculateResourceSize(after.metadata.resources || []),
    sizeReduction: calculateSizeReduction(before.metadata.resources || [], after.metadata.resources || [])
  },
  fileSize: {
    beforeMB: parseFloat((fs.statSync(beforePath).size / 1024 / 1024).toFixed(2)),
    afterMB: parseFloat((fs.statSync(afterPath).size / 1024 / 1024).toFixed(2)),
    reduction: parseFloat(((fs.statSync(beforePath).size - fs.statSync(afterPath).size) / fs.statSync(beforePath).size * 100).toFixed(2))
  },
  timestamps: {
    before: before.metadata.startTime,
    after: after.metadata.startTime
  }
};

// Helper functions
function calculateResourceSize(resources) {
  return parseFloat((resources.reduce((sum, r) => sum + (r.content?.length || 0), 0) / 1024).toFixed(2));
}

function calculateSizeReduction(beforeRes, afterRes) {
  const beforeSize = beforeRes.reduce((sum, r) => sum + (r.content?.length || 0), 0);
  const afterSize = afterRes.reduce((sum, r) => sum + (r.content?.length || 0), 0);
  return beforeSize > 0 ? parseFloat(((beforeSize - afterSize) / beforeSize * 100).toFixed(2)) : 0;
}

// Save analysis
fs.writeFileSync('analysis-data.json', JSON.stringify(analysis, null, 2));
console.log('‚úì Analysis completed and saved to analysis-data.json');
```

**Requirements:**
- Replace `[PATH_TO_BEFORE_TRACE]` and `[PATH_TO_AFTER_TRACE]` with actual paths
- Run the script: `node analyze-traces.js`
- Verify `analysis-data.json` is created

### Step 5: Extract and Calculate Metrics

From the analysis, extract the following metrics:

#### Core Metrics
1. **Duration (Loading Time)**
   - BEFORE: `metadata.modifications.initialBreadcrumb.window.range` (in microseconds)
   - AFTER: Same structure
   - Convert to milliseconds: `value / 1000`
   - Calculate improvement: `((before - after) / before) * 100`

2. **Total Events**
   - BEFORE: `traceEvents.length`
   - AFTER: Same
   - Calculate reduction: `((before - after) / before) * 100`

3. **Resources**
   - BEFORE: `metadata.resources.length`
   - AFTER: Same
   - Calculate total size in KB: Sum of `resource.content.length / 1024`
   - Calculate reduction percentage

4. **File Size**
   - BEFORE: File size in MB
   - AFTER: File size in MB
   - Calculate reduction: `((before - after) / before) * 100`

5. **Timestamps**
   - BEFORE: `metadata.startTime`
   - AFTER: `metadata.startTime`

#### Derived Metrics (Estimated)
Based on duration improvements, estimate:
- **FCP (First Contentful Paint):** ~30% of duration improvement
- **LCP (Largest Contentful Paint):** ~40% of duration improvement
- **TBT (Total Blocking Time):** ~50% of event reduction
- **CLS (Cumulative Layout Shift):** Based on image optimization presence

### Step 6: Generate Reports

Create the following files in `new-site/Traces/Reports/`:

#### 6.1 Main Report: `performance-analysis-report.md`

**Structure:**
```markdown
# Relat√≥rio de An√°lise de Performance - [PROJECT_NAME]

**Data da An√°lise:** [CURRENT_DATE]
**Projeto:** [PROJECT_NAME]
**Objetivo:** Comparar m√©tricas de performance antes e depois da implementa√ß√£o de otimiza√ß√µes

---

## üìä Sum√°rio Executivo

[Summary paragraph describing the analysis and main findings]

### üéØ Resultados Principais

| M√©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| **Tempo de Carregamento** | [X] ms | [Y] ms | **‚¨áÔ∏è [Z]%** |
| **Total de Eventos** | [X] | [Y] | **‚¨áÔ∏è [Z]%** |
| **Tamanho do Trace** | [X] MB | [Y] MB | **‚¨áÔ∏è [Z]%** |
| **Recursos Inline** | [X] KB | [Y] KB | **‚¨áÔ∏è [Z]%** |

---

## üìà An√°lise Detalhada

### 1. Performance de Carregamento

[Detailed analysis of loading time improvements]

```mermaid
graph LR
    A[Antes: X ms] -->|Otimiza√ß√£o| B[Depois: Y ms]
    B -->|Economia| C[Z ms]
    
    style A fill:#ff6b6b
    style B fill:#51cf66
    style C fill:#ffd93d
```

#### Breakdown por Fase

[Detailed breakdown table]

**Impacto para o Usu√°rio:**
- [List user-facing impacts]

---

### 2. Complexidade de Eventos do Browser

[Analysis of browser events reduction]

```mermaid
pie title Distribui√ß√£o de Eventos (Redu√ß√£o)
    "Eventos Removidos" : [X]
    "Eventos Mantidos" : [Y]
```

---

### 3. Otimiza√ß√£o de Recursos

[Analysis of resource optimization]

```mermaid
graph TD
    A[Recursos Antes] --> B[...]
    F[Recursos Depois] --> G[...]
    
    style A fill:#ff6b6b
    style F fill:#51cf66
```

---

### 4. Tamanho do Arquivo Trace

[Analysis of trace file size reduction]

---

## üîç An√°lise T√©cnica Detalhada

### Timestamps dos Traces

[Timestamps table]

### Mudan√ßas Arquiteturais Identificadas

#### ANTES (Vers√£o Original)
[Code comparison or description]

#### DEPOIS (Vers√£o Otimizada)
[Code comparison or description]

---

## üìä M√©tricas Web Vitals (Estimadas)

| M√©trica | Meta | Antes (Est.) | Depois (Est.) | Status |
|---------|------|--------------|---------------|--------|
| **FCP** | < 1.8s | ~[X]s | **~[Y]s** | [‚úÖ/‚ùå] |
| **LCP** | < 2.5s | ~[X]s | **~[Y]s** | [‚úÖ/‚ùå] |
| **TBT** | < 200ms | ~[X]ms | **~[Y]ms** | [‚úÖ/‚ùå] |
| **CLS** | < 0.1 | ~[X] | **~[Y]** | [‚úÖ/‚ùå] |

---

## üí° Otimiza√ß√µes Implementadas

[List of optimizations with checkmarks]

---

## üéì Li√ß√µes Aprendidas

[Key insights from the analysis]

---

## üìà ROI da Otimiza√ß√£o

### Tempo Investido
[Estimated time]

### Benef√≠cios Obtidos
[List of benefits]

### ROI Estimado
[ROI calculation]

---

## üöÄ Pr√≥ximos Passos

### Curto Prazo (1-2 semanas)
[List of short-term recommendations]

### M√©dio Prazo (1-2 meses)
[List of medium-term recommendations]

### Longo Prazo (3+ meses)
[List of long-term recommendations]

---

## üìö Refer√™ncias
[Links to documentation and tools]

---

## üìä Anexos
[Links to data files and scripts]

---

## ‚úçÔ∏è Conclus√£o
[Final summary and recommendation]
```

**Requirements:**
- Use Mermaid diagrams for visualizations
- Include all metrics from analysis-data.json
- Provide actionable insights
- ~40 pages of comprehensive analysis

#### 6.2 Executive Summary: `executive-summary.md`

**Structure:**
```markdown
# üìä Performance Optimization - Executive Summary

## [PROJECT_NAME]

**Data:** [CURRENT_DATE]
**Status:** ‚úÖ **Otimiza√ß√µes [Bem-Sucedidas/Parciais/etc]**

---

## üéØ Resultados em N√∫meros

[Summary table]

---

## üìà Visualiza√ß√£o de Impacto

### Tempo de Carregamento
[ASCII progress bars]

---

## ‚úÖ Principais Otimiza√ß√µes

[Categorized list of optimizations]

---

## üéì Key Insights

[Table of key insights]

---

## üìä Web Vitals (Estimados)

[Web Vitals summary table]

---

## üí° ROI

### Investimento
[Time and resources]

### Retorno
[Benefits and improvements]

**Payback:** [Estimated payback period]

---

## üöÄ Pr√≥ximos Passos

[Categorized next steps]

---

## ‚úÖ Recomenda√ß√£o Final

**[APROVAR/REVISAR/REJEITAR] PARA PRODU√á√ÉO**

[Justification]
```

**Requirements:**
- Concise (2-3 pages)
- Executive-friendly language
- Clear recommendations

#### 6.3 Visual Dashboard: `visual-dashboard.md`

**Structure:**
```markdown
# üìä Performance Dashboard - Visual Comparison

## [PROJECT_NAME] - Antes vs Depois das Otimiza√ß√µes

---

## üéØ Score Card

[ASCII art scorecards for BEFORE and AFTER]

---

## üìä Gr√°ficos de Compara√ß√£o

### Tempo de Carregamento (ms)
[ASCII bar chart]

### Total de Eventos
[ASCII bar chart]

### Tamanho do Trace (MB)
[ASCII bar chart]

---

## üé® Progress Bars

[Multiple progress bars showing improvements]

---

## üèÜ Web Vitals Radar Chart

[ASCII radar chart or alternative visualization]

---

## üìà Timeline Comparison

[ASCII timeline showing loading phases]

---

## üéØ Impact Matrix

[ASCII matrix showing impact vs complexity]

---

## üî• Performance Heatmap

[ASCII heatmap of different performance categories]

---

## üíØ Overall Performance Score

[Score breakdown with ASCII visualization]

---

## üéä Achievement Unlocked!

[Celebration box if all metrics improved]

---

## üìä Summary Table

[Comprehensive summary table]

---

## üéØ Conclus√£o Visual

[Visual summary with emojis and ASCII art]
```

**Requirements:**
- Heavy use of ASCII art and emojis
- Visual and engaging
- 6-7 pages

#### 6.4 Data Export: `metrics-data.csv`

**Structure:**
```csv
M√©trica,Antes,Depois,Unidade,Melhoria (%),Melhoria Absoluta
Tempo de Carregamento,[X],[Y],ms,[Z],[A]
Total de Eventos,[X],[Y],eventos,[Z],[A]
...

Web Vitals (Estimados),Antes,Depois,Unidade,Meta,Status
First Contentful Paint,[X],[Y],ms,< 1800,[Status]
...

Otimiza√ß√µes Implementadas,Status,Impacto,Categoria
[Optimization],[Status],[Impact],[Category]
...

Pr√≥ximos Passos,Prioridade,Prazo,Impacto Estimado
[Step],[Priority],[Timeframe],[Impact]
...
```

**Requirements:**
- CSV format for easy import to Excel/Google Sheets
- Multiple sections separated by blank lines
- Clear headers

#### 6.5 Reports Index: `README.md`

**Structure:**
```markdown
# üìä Performance Analysis Reports

Esta pasta cont√©m an√°lises detalhadas de performance do [PROJECT_NAME] baseadas em Chrome DevTools Performance Traces.

## üìÅ Arquivos Dispon√≠veis

### üìÑ Relat√≥rios
1. **performance-analysis-report.md** ‚≠ê **RECOMENDADO**
2. **executive-summary.md**
3. **visual-dashboard.md** üé® **VISUAL**

### üìä Dados
4. **../analysis-data.json**
5. **metrics-data.csv**

### üî¨ Scripts
6. **../analyze-traces.js**

## üéØ Quick Start

[Quick start commands]

## üìà Principais Descobertas

[Summary table]

## üîó Links R√°pidos

[Links to related documents]

## üìÖ Hist√≥rico de Vers√µes

[Version history table]
```

### Step 7: Create Main Traces README

Create `new-site/Traces/README.md`:

**Structure:**
```markdown
# üìä Performance Traces - [PROJECT_NAME]

Esta pasta cont√©m **Chrome DevTools Performance Traces** do [PROJECT_NAME], capturados antes e depois da implementa√ß√£o de otimiza√ß√µes de performance.

## üìÅ Estrutura de Pastas

[Directory tree]

## üéØ In√≠cio R√°pido

[Quick start guide]

## üìà Resultados Principais

[Results table]

## üîç Sobre os Traces

### Trace ANTES
[Details about BEFORE trace]

### Trace DEPOIS
[Details about AFTER trace]

## üìö Documenta√ß√£o Relacionada

[Links to related specs/docs]

## üõ†Ô∏è Ferramentas Utilizadas

[Tools and methodology]

## üìä Como Ler os Traces

[Instructions for opening and analyzing traces in DevTools]

## üéØ Otimiza√ß√µes Implementadas

[List of optimizations]

## üìû Suporte

[Contact information]

## üìÖ Hist√≥rico

[History table]
```

### Step 8: Generate Visualizations

For each report, include:

1. **Mermaid Diagrams** (in markdown files):
   - Flow charts showing before/after
   - Pie charts for event distribution
   - Gantt charts for loading timeline
   - Graphs for metric comparisons

2. **ASCII Art** (in visual-dashboard.md):
   - Bar charts using blocks (‚ñà)
   - Progress bars with percentages
   - Score cards with borders
   - Heatmaps with symbols

3. **Tables**:
   - Comparison tables (Before | After | Improvement)
   - Web Vitals status tables
   - Optimization checklist tables
   - ROI breakdown tables

### Step 9: Calculate Estimations

When actual Web Vitals data is not available in traces, estimate based on:

1. **FCP (First Contentful Paint)**:
   - Baseline: ~30% of total duration for unoptimized
   - Optimized: Reduce by ~50% if CDNs removed
   - Formula: `(totalDuration * 0.3) ‚Üí (totalDuration * 0.15)`

2. **LCP (Largest Contentful Paint)**:
   - Baseline: ~40% of total duration
   - Optimized: Reduce by ~45% if image optimization + preload
   - Formula: `(totalDuration * 0.4) ‚Üí (totalDuration * 0.22)`

3. **TBT (Total Blocking Time)**:
   - Correlate with event reduction
   - More events = more blocking
   - Formula: `baselineTBT * (1 - eventReduction%)`

4. **CLS (Cumulative Layout Shift)**:
   - Check for image width/height attributes in resources
   - Look for layout-shift events in traces
   - Estimate improvement if images were optimized

### Step 10: Provide Recommendations

Based on the analysis, categorize recommendations into:

#### Curto Prazo (1-2 semanas)
- Quick wins with high impact
- Low complexity optimizations
- Examples: Image optimization, font subsetting, Service Worker

#### M√©dio Prazo (1-2 meses)
- Moderate complexity optimizations
- Infrastructure changes
- Examples: CDN migration, HTTP/2 Server Push, Critical CSS inline

#### Longo Prazo (3+ meses)
- Complex implementations
- Architectural changes
- Examples: PWA, Performance monitoring, A/B testing framework

### Step 11: Quality Checks

Before finalizing reports:

1. **Verify Data Accuracy**:
   - ‚úÖ All calculations are correct
   - ‚úÖ Percentages add up
   - ‚úÖ No negative values where impossible

2. **Check Formatting**:
   - ‚úÖ All Mermaid diagrams render correctly
   - ‚úÖ Tables are properly aligned
   - ‚úÖ ASCII art displays correctly in monospace font
   - ‚úÖ Links are valid and working

3. **Validate Content**:
   - ‚úÖ All sections are complete
   - ‚úÖ No placeholder text remains ([X], [Y], etc.)
   - ‚úÖ Timestamps are accurate
   - ‚úÖ File paths are correct

4. **Review Insights**:
   - ‚úÖ Recommendations are actionable
   - ‚úÖ Insights are data-driven
   - ‚úÖ Conclusions are justified by metrics

### Step 12: Final Output Summary

Present to the user:

```markdown
## ‚úÖ An√°lise de Performance Completa!

Criei uma **an√°lise de melhoria completa e detalhada** comparando os dois traces de performance.

### üìä Resultados Principais

| M√©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| [Summary table with actual values]

### üìÅ Arquivos Criados em `Traces/Reports/`

1. **performance-analysis-report.md** ‚≠ê **PRINCIPAL**
   - [Brief description]

2. **executive-summary.md**
   - [Brief description]

3. **visual-dashboard.md** üé®
   - [Brief description]

4. **metrics-data.csv**
   - [Brief description]

5. **README.md**
   - [Brief description]

### üî¨ Arquivos de An√°lise

- **analyze-traces.js** - [Description]
- **analysis-data.json** - [Description]
- **README.md** - [Description]

### üéØ Destaques da An√°lise

‚úÖ **[Key achievement 1]**
‚úÖ **[Key achievement 2]**
‚úÖ **[Key achievement 3]**

[Additional summary points]

Os relat√≥rios est√£o prontos para visualiza√ß√£o e incluem diagramas Mermaid, tabelas comparativas, gr√°ficos ASCII e toda a documenta√ß√£o necess√°ria! üéâ
```

## Error Handling

### Missing or Invalid Traces
If traces are missing or invalid:
1. Clearly state what's missing/invalid
2. Provide example of correct trace structure
3. Ask user to provide correct files

### Incomplete Data
If trace files lack expected metadata:
1. Note which metrics cannot be calculated
2. Calculate what's possible
3. Document limitations in reports
4. Mark missing data with "[N/A - Data not available]"

### File System Errors
If unable to create files:
1. Report specific error
2. Suggest alternative approaches (e.g., output to conversation)
3. Offer to create files one at a time

## Customization Options

User can optionally specify:
- **Project name:** Default to workspace name
- **Report title:** Custom title for reports
- **Analysis focus:** Specific metrics to emphasize
- **Comparison context:** What optimizations were made
- **Output location:** Alternative path for reports

## Best Practices

1. **Be Thorough:** Don't skip steps even if they seem obvious
2. **Verify Data:** Double-check all calculations
3. **Provide Context:** Explain what metrics mean for non-technical readers
4. **Be Actionable:** All recommendations should be specific and implementable
5. **Celebrate Wins:** If metrics improved, highlight the success
6. **Be Honest:** If metrics worsened, analyze why and recommend fixes

## Example Usage

```
User: /analyze-traces
[Attaches trace-before.json and trace-after.json]

Copilot:
‚úÖ Received 2 trace files. Analyzing...

BEFORE: trace-before.json (captured 2026-01-26 10:12:09)
AFTER: trace-after.json (captured 2026-01-26 12:26:13)

[Executes all steps 1-12]

‚úÖ Analysis complete! Generated:
- performance-analysis-report.md (40 pages)
- executive-summary.md (3 pages)
- visual-dashboard.md (7 pages)
- metrics-data.csv
- All supporting files

üìä Key Results:
- Loading time: -23.26% faster
- Browser events: -32.98% reduction
- All Web Vitals in "Good" range

Reports ready for review in Traces/Reports/
```

---

**Last Updated:** January 26, 2026
**Version:** 1.0
**Command:** `/analyze-traces`
